{
    "project": "code-copilot",
    "task_config": {
        "name": "code-explanation"
    },
    "client_config": {
        "client_name": "anyscale",
        "client_type": "third_party_llm",
        "model_name": "meta-llama/Meta-Llama-3-70B-Instruct",
        "model_type": "llama-3-70b",
        "model_options": {
            "temperature": 0,
            "top_p": 1,
            "max_tokens": 8192
        }
    },
    "prompt_config": {
        "name": "code-explain",
        "tenant": "nns",
        "path": "prompts/code_explanation/prompt.yaml",
        "version": 1
    },
    "evaluator_config": {
        "metrics": [
            {
                "type": "accuracy",
                "aspect": "code-explanation"
            },
            {
                "type": "latency"
            },
            {
                "type": "cost"
            }
        ]
    },
    "dataset_config": {
        "data_path": "datasets/code_explanation/python_desc_df.csv",
        "label_col": "label",
        "sanity_test": true
    },
    "controller_config": {
        "save_path": "results/code_explanation/python",
        "parallelism": 12,
        "use_streaming": false,
        "save_inference": true
    }
}