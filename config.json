{
  "project": "llm-validation",
  "task_config": {
    "name": "code-generation"
  },
  "client_config": {
    "name": "openai",
    "type": "research",
    "model_name": "gpt-4o-mini",
    "base_url": "",
    "model_options": {}
  },
  "prompt_config": {
    "name": "code-generation-prompt-v1",
    "path": "prompts/code_generation.yaml",
    "version": 1
  },
  "evaluator_config": {
    "metrics": [
      {
        "type": "accuracy",
        "aspect": "codegen",
        "kwargs": {}
      },
      {
        "type": "latency",
        "aspect": "",
        "kwargs": {}
      },
      {
        "type": "cost",
        "aspect": "",
        "kwargs": {}
      }
    ],
    "llm_judge": null
  },
  "dataset_config": {
    "data_path": "datasets/code_generation/test.csv",
    "label_col": "true_label"
  },
  "controller_config": {
    "parallelism": 12,
    "use_streaming": true,
    "save_path": "results"
  }
}